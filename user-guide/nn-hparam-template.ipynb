{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1d0669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double checking dataset sizes:\n",
      "\n",
      "Training set x size: (25534, 354). Training set y size: (25534, 3)\n",
      "\n",
      "validation set x size: (3103, 354). Validation set y size: (3103, 3)\n",
      "\n",
      "Testing set x size: (3238, 354). Testing set y size: (3238, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "source_loc = \"/project/wyin/jlee/ml-project/source\"\n",
    "sys.path.append(source_loc)\n",
    "from utilities import ProblemStatement, UnscaledData, ScaledData, order_validation\n",
    "\n",
    "data_loc, X_name, y_name = ProblemStatement().prob_vars\n",
    "data = ScaledData(data_loc, X_name, y_name, check_data = True)    #Set check_data to False to suppress output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43480253",
   "metadata": {},
   "source": [
    "Create the hyperparameter folder if it doesn't exist yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a14019fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"hyperparameters\"):\n",
    "    os.mkdir(\"hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51cce0",
   "metadata": {},
   "source": [
    "Name this grid search run, and whether to save the resulting models.\n",
    "Set hyperparameters for grid search here: \n",
    "\n",
    "1. layer_sizes: Architecture of the network, set as a list of lists, with each list element representing the sequential neuron numbers in each layer\n",
    "2. learning_rate: Set as list of starting learning rates\n",
    "3. batch_size: Set as list of batch sizes\n",
    "4. schedule_factor: Set as list of factors. Factor determines how much the learning rate reduces on loss plateau\n",
    "5. max_time: Set as \"DD:HH:MM:SS\" string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32eeb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"test-4\"\n",
    "save_models = True\n",
    "\n",
    "layer_sizes = [[354, 256, 128, 64, 32, 3], [354, 256, 140, 50, 3]]\n",
    "learning_rate = [0.001, 0.005, 0.01]\n",
    "batch_size = [128, 256]\n",
    "schedule_factor = [0.2, 0.5]\n",
    "max_time = \"00:00:00:30\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c2a7a",
   "metadata": {},
   "source": [
    "Save the settings for the grid search to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd71001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"hyperparameters/grid-search\",\"wb\")\n",
    "\n",
    "settings = {'layer_sizes': layer_sizes, 'learning_rate': learning_rate, \n",
    "           'batch_size': batch_size, \"schedule_factor\": schedule_factor, \n",
    "            'max_time': max_time, 'run_name': run_name, 'save_models': save_models}\n",
    "pickle.dump(settings, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1a38a",
   "metadata": {},
   "source": [
    "To run the grid search over the neural network models, run the following from the command line in the source folder:\\\n",
    "sbatch nn-runner.sbatch {total models to run} {location of problem definition file} {hyperparameter folder} {name of run}\n",
    "<br /><br />\n",
    "To see the models training in tensorboard, run:\\\n",
    "tensorboard --logdir {hyperparameter folder}/logs/{name of run}\n",
    "<br /><br />\n",
    "You can copy the outputs of the code snippet below and run it in command line in the source folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eacc7b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run in command line to train models: \n",
      "sbatch nn-runner.sbatch 24 /project/wyin/jlee/ml-project/user-guide/problem-definition.txt /project/wyin/jlee/ml-project/user-guide/hyperparameters test-4\n",
      "\n",
      "Run in command line to see tensorboard: \n",
      "tensorboard --logdir /project/wyin/jlee/ml-project/user-guide/hyperparameters/logs/test-4\n"
     ]
    }
   ],
   "source": [
    "prob_file = os.path.join(os.getcwd(), \"problem-definition.txt\")\n",
    "hparam_loc = os.path.join(os.getcwd(), \"hyperparameters\")\n",
    "log_loc = os.path.join(hparam_loc, \"logs\", run_name)\n",
    "val_loc = os.path.join(hparam_loc, \"val-ends\", run_name)\n",
    "\n",
    "num_models = len(layer_sizes) * len(learning_rate) * len(batch_size) * len(schedule_factor)\n",
    "\n",
    "print(f\"Run in command line to train models: \\nsbatch nn-runner.sbatch {num_models} {prob_file} {hparam_loc} {run_name}\\n\")\n",
    "\n",
    "print(f\"Run in command line to see tensorboard: \\ntensorboard --logdir {log_loc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf0130",
   "metadata": {},
   "source": [
    "Once the models are finished training, you can see models sorted by best validation loss by using order_validation({log folder}). You can also get the absolute file location of the best performing model - useful for model evaluation (see other jupyter notebook), assuming you saved the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "065491e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: [354, 256, 128, 64, 32, 3], 0.01, 256, 0.2, error: 8.90369756234577e-06\n",
      "model: [354, 256, 128, 64, 32, 3], 0.001, 256, 0.2, error: 9.854635209194385e-06\n",
      "model: [354, 256, 128, 64, 32, 3], 0.001, 128, 0.2, error: 2.1584812202490866e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.005, 128, 0.5, error: 2.194699482060969e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.001, 128, 0.5, error: 2.619006590975914e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.005, 256, 0.2, error: 3.1832056265557185e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.001, 256, 0.5, error: 3.234771793358959e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.01, 256, 0.5, error: 3.2730389648349956e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.005, 256, 0.5, error: 3.341983392601833e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.005, 128, 0.2, error: 4.23714991484303e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.01, 128, 0.2, error: 7.63205680414103e-05\n",
      "model: [354, 256, 128, 64, 32, 3], 0.01, 128, 0.5, error: 0.00021948710491415113\n",
      "\n",
      "Best model location: /project/wyin/jlee/ml-project/user-guide/hyperparameters/logs/test-4/[354, 256, 128, 64, 32, 3], 0.01, 256, 0.2\n"
     ]
    }
   ],
   "source": [
    "errors = order_validation(val_loc)\n",
    "\n",
    "for error, model in errors:\n",
    "    print(f\"model: {model}, error: {error}\")\n",
    "    \n",
    "print(f\"\\nBest model location: {os.path.join(log_loc, errors[0][1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
